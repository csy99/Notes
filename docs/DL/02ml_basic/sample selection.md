# 样本选择

选择最少量的训练集S$\sub$完整训练集T，模型效果不会变差。

优势：

- 缩减模型计算时间
- 相关性太低的数据对解决问题没有帮助，直接剔除
- 去除噪声



### 数据去噪

**噪声数据**

1. 特征值不对（缺失、超出值域范围），可能提升模型健壮性
2. 标注不对，降低数据质量。

#### 处理方法

基于融合或者投票的思想

1. 集成过滤法Ensemble Filter
2. 交叉验证委员会过滤法Cross-Validated Committees Filter
3. 迭代分割过滤法Iterative-Partitioning Filter

基于业务本身

1. 清洗爬虫数据
2. 过滤掉无效曝光
3. 过滤掉最后一次点击之后的展示（用户可能没看到）



### 采样

**优点**

- 克服高维特征以及大量数据导致的问题，缩短时间
- 在不平衡分类问题中帮助平衡样本比例

#### 计算样本大小

$P(|e-e_0|\geq\epsilon) \leq \delta$

e代表样本的估计，通常是样本大小n的函数。

$e_0$代表真实样本，一般未知

#### 采样方法

目标：无偏性Unbiasedness + 小样本方差 Sampling Variance

1. 无放回简单随机抽样
2. 有放回简单随机抽样
3. 平衡采样
4. 整群采样
5. 分层采样



### 原型选择和悬链及选择

原型选择

在样本选择过程中不需要训练模型，只选取相似度指标来找到分类精度和数据量最佳的训练集，多采用KNN算法。

训练集

构建预测模型来进行样本选择的方法，比如决策树和SVM等算法。



# 验证

### 留出法

概念：

随机划分成两份互斥的数据集。

优点：

- 时间序列数据可用早一些的数据做训练集，晚一些的做测试集

缺点：

- 不能充分利用数据训练模型
- 划分结果严重影响最终结果

解决方案：

- 多次留出，将多次得到的实验结论进行平均

### K折交叉验证

概念：

平均分成K份，每次用一份数据测试，其余数据训练。K=N时，就是留一法Leave One Out (LOO)。还有一种变体是分层K折，适用于不均衡分类问题。

优点：

- 数据利用率高

缺点：

- 稳定性和K取值有关。太小则稳定性偏低，太大则实验成本搞。

### 自助法 Bootstrapping

概念：

自主采样，有放回的重复采样，构建n条样本的训练集。一些样本在训练集重复出现，另一些没有出现的作为测试集。适用于数据量比较小。

每条样本没被采到的概率$P_0 =  1 - \frac{1}{n}$，经过n次采样还没有采到的概率是$lim_{n->+\infty}(1-\frac{1}{n})^n = e^{-1} = 0.368$

优点：

- 解决了其他采样得到的模型会因为训练集大小不一致产生一定偏差的问题

缺点：

- 改变了初始数据集分布，引入估计偏差



# Reference

- 《美团机器学习实践》by美团算法团队，第一章
- 《机器学习》by周志华，第二章