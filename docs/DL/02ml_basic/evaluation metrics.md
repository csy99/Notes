# 评估指标

线下使用机器学习评估指标，线上使用的是业务指标。需要进行多轮模型迭代使两个指标变化趋势相同。  

## 分类指标

### 精确率和召回率

用于二分类问题，结合混淆矩阵。   

精确率 P = $\frac{TP}{TP+FP}$
召回率 R = $\frac{TP}{TP+FN}$  

精确率：也称作查准率。在被识别为正类别的样本中，确实是正类别的比例。

召回率：也成为查全率。在所有正类别样本中，被正确识别为正类别的比例

以召回率R为横轴，以精确率P为纵轴画P-R曲线，越靠近右上角性能越好。曲线下的面积为AP分数(Average Precision Score)  。

<img src="./pics/01prcurve.PNG" width="300" height="270">

如果一个PR曲线完全包含另一个，则前者性能更优。如果两个曲线发生交叉，则比较平衡点，远离原点的更好。



### F值

$\frac{2}{F_1} = \frac{1}{P} + \frac{1}{R}$

可泛化成为$F_\alpha = \frac{(1+\alpha^2)*P*R}{\alpha^2*P+R}$

在不同的情况下，对精准率和召回率的偏重是不一样的，如在推荐系统中，为了尽可能少打扰用户，更希望推荐的内容是用户喜欢的，这时，精准率比较重要；而在逃犯检索系统中，更希望尽可能少漏掉逃犯，此时召回率比较重要。

当参数$\alpha$>1时，召回率有更大影响，可以考虑为，$\alpha$无穷大时，分母中的R和分子中的1都可忽略不计，则F=R，只有召回率起作用。



### 准确率和错误率

不要将精确率和准确率搞混。准确率是模型预测正确的结果所占的比例。而且精确率仅仅适用于二分类概念。

训练集的错误率可以衍生出经验风险(empirical risk)。测试集的错误率也被称作泛化误差(generalization error)。

### ROC

接受者操作特征 Receiver Operating Characteristic (ROC)

解决了使用精确率等指标进行模型评估时，需要对预测概率设分类阈值，增添超参数，的问题。

真正率 TPR = $\frac{TP}{TP+FN}$  

假正率 FPR = $\frac{FP}{FP+TN}$   

以假正率为x轴，以真正率为y轴，ROC曲线越靠近左上角越好。此时TPR=1，FPR=0。在采用有限测试样例绘制ROC图时，无法画出光滑曲线。过程：给定$m_1$个正例和$m_2$个反例，根据预测结果对样例进行排序，把分类阈值设为最大，即把所有样例均预测成为反例，此时TPR=FPR=0，在(0,0)处标记一个点。然后，将分类阈值依次设为每个样例的预测值，依次将每个样例划分为正例。设前一个标记点坐标为$(x,y)$，当前若为真正例，则对应标记点坐标为$(x,y+\frac{1}{m_1})$，否则对应标记点坐标为$(x+\frac{1}{m_2},y)$。用线段连接相邻点。

<img src="./pics/roc.png" height="350">

相较于PR曲线，ROC曲线在正负样本的分布发生变化时更容易保持稳定。

### AUC

Area Under ROC Curve (AUC)是指ROC曲线下的面积。取值越大，说明模型越可能将正样本放在负样本前面。AUC计算主要与排序有关，对预测分数没那么敏感。

$l_{rank}  = \frac{1}{m_1+m_2} \sum_{x^+}\sum_{x^-} I(f(x^+)<f(x^-) + 0.5I(f(x^+) = f(x^-)))$

$AUC = 1-l_{rank}$

在非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价，而代价曲线可以。横轴是取值为[0,1]的正例概率代价，纵轴是取值为[0,1]的归一化代价。

$cost_{01}, cost_{10}$ 分别代表type one error和type two error。

$P(+)cost = \frac{p*cost_{01}}{p*cost_{01} + (1-p)*cost_{10}}$

$cost_{norm} = \frac{FNR*p*cost_{01} + FPR*(1-p)*cost_{10}}{p*cost_{01} + (1-p)*cost_{10}}$



### 对数损失

logistic loss = $-logP(Y|X)$ = $-\frac{1}{NC}\sum_{i=0}^N\sum_{j=0}^C{y_{ij}*logp_{ij}}$

衡量预测概率分布和真实概率分布的差异性。取值越小越好。对预测概率敏感。



## 回归指标

### 平均绝对误差

平均绝对误差Mean Absolute Error，也称为L1范数损失。

MAE = $\frac{1}{N}\sum_{i=0}^N{|y_i-p_i|}$

对数据分布的中值进行拟合。

缺点：

- 有些模型（如XGBoost）必须要求损失函数有二阶导，不能直接优化MAE。

加权平均绝对误差Weighted Mean Absolute Error是其变种。比如可以考虑时间因素。

WMAE = $\frac{1}{N}\sum_{i=0}^N{w_i|y_i-p_i|}$



### 平均绝对百分误差

MAPE = $\frac{100}{N}\sum_{i=0}^N{\frac{|y_i-p_i|}{y_i}}$，要求$y_i\neq0$

优点：

- 其计算与量纲无关，易于比较。

缺点：

- 对负值误差的惩罚大于正值误差（因为分母y小了）。
- 在$y_i$ = 0处无定义，或者太小的时候导致MAPE过大



### 均方根误差

对数据分布的平均值进行拟合。

RMSE = $\sqrt{\frac{1}{N}\sum_{i=0}^N{(y_i-p_i)^2}}$

缺点：

- 对大误差样本有更大惩罚。有可能模型在95%的情况下都有较好的预测结果，但是剩下的情况导致模型的RMSE一直居高不下。
- 对离群点敏感，健壮性不如MAE。



### 均方根对数误差

Root Mean Squared Logarithmic Error (RMSLE)

RMSLE = $\sqrt{\frac{1}{N}\sum_{i=0}^N{(log(y_i+1)-log(p_i+1))^2}}$

缺点：

- 对预测值偏小的样本惩罚比对预测值偏大的样本惩罚更大。

- 有可能无法直接优化RMSLE，但是若可以优化RMSE，可以先对预测目标进行对数变换$y_{new}=log(y+1)$。



## 排序指标

// TODO

### 平均准确率均值

Mean Average Precision (MAP)

公式分两部分计算

AP@K = 



### 归一化贴现累计收益

Normalized Discounted Cumulative Gain (NDCG)



### 比较检验

#### 假设检验

我们不知道学习器泛化错误率，只能知道测试错误率。设泛化错误率是$\epsilon$，测试错误率是$\hat\epsilon$, 测试样本为m，其中有e个样本被误分类。则该学习器被测出来测试错误率为$\hat\epsilon$的概率是$P(\hat\epsilon;\epsilon)=C(m, \hat\epsilon*m)\epsilon^{\hat\epsilon*m}(1-\epsilon)^{m-\hat\epsilon}$. 

#### 交叉验证t test

可采用5*2交叉验证：做5次2折交叉验证。每次2折交叉验证之前随即将数据打乱。

$t = \frac{\mu}{\sqrt{0.2\sum_{i=1}^5\sigma_i^2}}$

#### McNemar检验

若我们假设两学习器性能相同，应该有$e_{01}$ = $e_{10}$（下标分别表示两个学习器分类是否正确的情况）. 变量|$e_{01}$-$e_{10}$|应当服从正态分布，均值为1，方差为$e_{01}$+$e_{10}$。称作卡方分布。

#### Friedman检验与Nemenyi后续检验

在一组数据集上比较多组算法。



## 距离



### 余弦距离

在文本、图像等领域，研究的对象特征维度很高，余弦相似度应用较广。欧氏距离的数值受到维度影响较大，范围不固定，含义比较模糊。



# Reference

- 《美团机器学习实践》by美团算法团队，第一章
- 《机器学习》by周志华，第二章
- 《百面机器学习：算法工程师带你去》by葫芦娃，第二章